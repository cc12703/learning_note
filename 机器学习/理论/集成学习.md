
# 集成学习

[TOC]

## 概述

### 思想
* 用训练数据，训练出若干个个体学习器
* 通过一定的结合策略，最终形成一个强学习器

### 主要问题
#### 如何选择个体学习器
* 同质的：所有的学习器都是同一种类型
    * 应用最广泛
    * 最多的类型是 CART决策树、神经网络
* 异质的：所有的学习器有多种类型

#### 如何整合个体学习器（同质）
* 学习器之间存在强依赖关系，需要串行生成
    * 算法：boosting
* 学习器之间不存在强依赖关系，可以并行生成
    * 算法：bagging、随机森林


### 方案
#### boosting系列
##### 原理
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210106221036.png)

##### 流程
1. 从训练集用初始权重训练出一个弱学习器
1. 根据弱学习器的学习误差率来更新训练样本的权重（误差率高的样本，权重变高）
1. 用调整后权重训练出下一个弱学习器，直到指定个数
1. 使用结合策略进行整合，得到最终的学习器

##### 特点
* 做对的样本，给较低权重
* 做错的样本，给较高权重，让模型更重视 

##### 问题
* 如何计算**学习误差率**
* 如何得到**权重系数**
* 如何更新样本权重
* 使用那种结合策略

##### 算法
* Adaboost
* 提升树系列


#### bagging系列
##### 原理
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210106222527.png)

##### 流程
1. 对训练集进行随机采样，训练出弱学习器
1. 使用结合策略进行整合，得到最终的学习器

##### 采样
* 自助采样法

##### 算法
* 随机森林


### 结合策略
#### 平均法
* 对若个弱学习器的输出进行平均，得到最终结果
* 通常用于数值类型的回归问题

##### 类型
* 算术平均
* 加权平均：每个弱学习器有一个权重


#### 投票法
* 通常用于分类问题

##### 类型
* 相对多数投票：数量最多的类别为最终类别
* 绝对多数投票：数量最多且超过半数的类别为最终类别


#### 学习法
* 结合时使用一个独立的学习器重新学习一次

##### 流程
* 训练时
    1. 训练弱学习器
    1. 使用弱学习器的学习结果作为输入，训练集的输出为输出，训练结合学习器
* 预测时
    1. 用弱学习器预测一次
    1. 将弱学习器的预测结果，用结合学习器再预测一次






## Adaboost

### 概述
#### 特点
* 即可用于分类，也可用于回归

#### 优点
* 分类精度高
* 不容易发生过拟合
* 作为二分类器时，构造简单，结果可解释

#### 缺点
* 对异常样本敏感

#### 弱分类器类型
* 使用最广泛的是决策树和神经网络
* 对于决策树，分类用CART分类树，回归用CART回归树


### 思路（二分类）
#### 样本权重
$$ D(k) = (\omega_{k1}, \omega_{k2}, ..., \omega_{km}) $$
$$ \omega_{1i} = \frac{1}{m}; i = 1,2,3,...,m $$
说明
* $k$表示第k个弱学习器
* $m$为训练样本总数

#### 学习误差率
$$
e_k = \sum_{i=1}^m \omega_{ki} I(G_k(x_i) \ne y_i)
$$
说明
* $y$ 输出为 -1， 1
* $G_k(x)$ 为弱分类器

#### 权重系数
$$
\alpha_k = \frac{1}{2} log \frac{1 - e_k}{e_k}
$$


#### 权重更新
$$
\omega_{k+1, i} = \frac{\omega_{k,i}}{Z_k} 
                   exp( - \alpha_k y_i G_k(x_i)) 
$$

$Z_k$是规范化因子
$$
Z_k = \sum_{i=1}^m \omega_{k,i} exp( - \alpha_k y_i G_k(x_i))
$$

#### 结合策略
* 使用加权表决法

$$
f(x) = sign(\sum_{k=1}^K \omega_k G_k(x))
$$


### 流程（二分类）
1. 初始化样本集权重
1. 循环处理 k = 1,2,3,...,K (K为迭代次数)
    1. 使用带权重的样本，训练出弱分类器
    1. 计算弱分类器的分类误差率
    1. 计算弱分类器的权重系数
    1. 更新样本集的权重
1. 构建最终的强分类器






## 随机森林

### 思想
* 生成多个不同的树模型，将结果平均

### 概念
* 森林：多个决策树
* 随机（二重随机性）
    * 随机数据采样，每颗树的训练数据来自数据集的一部分
    * 随机特征选择，每颗树选择所有特征的一部分

### 结果集成
* 分类任务求众数
* 回归任务求平均值

### 特点
* 并行形式：多个树模型之间是无关的，使用相同的参数
* 可以进行可视化展示
* 总是先使用最好的特征





[TOC]

# 概述

## 优点

**相对于传统编程技术有以下优点**

* 简化代码、提升执行表现（传统方案需要大量手动调整和超长规则列表）
* 找到一个解决方案（传统技术无法解决的问题）
* 自动适应新的数据
* 从海量数据中获得洞见（通过数据挖掘）


## 主要挑战

### 坏数据

* 训练数据数量不足
* 训练数据不具有代表性（采样噪声、采样偏差）
* 训练数据质量差（满是错误，异常值，噪声）
* 训练数据中包含太多无关特征（特征工程）

### 坏算法

* 过度拟合（训练数据上表现好，泛化差）
* 拟合不足



# 分类

**可以从不同的角度来分类**

## 角度1：训练期间是否需要监督


### 监督学习

#### 要点

* 训练时需要提供带有标记的数据
* 可以使用 训练/测试 方法来防止过拟合

#### 典型任务

* 分类任务：垃圾邮件过滤
* 回归任务：预测二手车价格

#### 算法

* K-近邻算法（KNN）
* 线性回归
* 逻辑回归
* 支持向量机（SVM）
* 决策树
* 神经网络

### 无监督学习

#### 要点

* 训练时使用无标记的数据
* 可以发现未知的东西

#### 典型任务

* 聚类任务：分组博客访客
* 数据可视化
* 降维任务
* 异常检测：检测异常信用卡交易
* 关联规则学习

#### 算法

* K-平均算法
* 主成分分析（PCA）
* Apriori

### 半监督学习

#### 要点

* 可以处理部分标记的训练数据
* 大部分都是无监督算法和监督算法的结合

#### 算法

* 深度信念网络（DBN）

### 强化学习

#### 要点

* 可以自行学习什么是最好的策略


## 角度2：是否可以进行增量学习


### 批量学习

#### 要点

* 必须使用所有数据进行训练，都是离线完成
* 训练需要花费大量资源和时间

### 在线学习

#### 要点

* 可以分批的提供数据进行训练，逐步累积学习成果
* 每一步的学习都很快速并且便宜

## 角度3：如何泛化

### 基于实例的学习

#### 要点

* 系统先完全记住学习示例
* 通过某种相似度度量方式将其泛化到新实例

### 基于模型的学习

#### 要点

* 先基于学习示例构建模型
* 使用模型进行预测



# 模型评估

* 目的：评估模型的泛化误差


## 度量指标

## 评估方法

### 数据分离

 * 将数据分成训练数据和测试数据
 * 训练数据用于训练算法
 * 测试数据用于评估算法

### k折交叉验证

* 评估机器学习算法的黄金准则

#### 原理

* 将数据分成k个子集
* 一个子集作为测试集，其他作为训练集

#### 优点

 * 用数据的不同部分来训练模型
 * 在相同的测试集上度量性能

## 步骤

1. 将数据分成训练集测试集
2. 在训练集上使用交叉验证，来选择模型和确定超参数
3. 使用训练集对选定的模型（确定的超参数）进行最终训练
4. 使用测试集来测量泛化误差
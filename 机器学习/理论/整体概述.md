
# 整体概述

[TOC]



## 优点

**相对于传统编程技术有以下优点**

* 简化代码、提升执行表现（传统方案需要大量手动调整和超长规则列表）
* 找到一个解决方案（传统技术无法解决的问题）
* 自动适应新的数据
* 从海量数据中获得洞见（通过数据挖掘）



## 主要挑战

### 坏数据
* 训练数据数量不足
* 训练数据不具有代表性（采样噪声、采样偏差）
* 训练数据质量差（满是错误，异常值，噪声）
* 训练数据中包含太多无关特征（特征工程）

### 坏算法
* 过度拟合（训练数据上表现好，泛化差）
* 拟合不足




## 分类

### 不同角度
* 训练期间是否需要监督
    * 监督学习
    * 无监督学习
    * 半监督学习
    * 强化学习
* 是否可以进行增量学习
    * 批量学习
    * 在线学习
* 如何泛化
    * 基于实例的学习
    * 基于模型的学习


### 监督学习
#### 要点
* 训练时需要提供带有标记的数据
* 可以使用 训练/测试 方法来防止过拟合

#### 典型任务
* 分类任务：垃圾邮件过滤
* 回归任务：预测二手车价格

#### 算法
* K-近邻算法（KNN）
* 线性回归
* 逻辑回归
* 支持向量机（SVM）
* 决策树
* 神经网络


### 无监督学习
#### 要点
* 训练时使用无标记的数据
* 可以发现未知的东西

#### 典型任务
* 聚类任务：分组博客访客
* 数据可视化
* 降维任务
* 异常检测：检测异常信用卡交易
* 关联规则学习

#### 算法
* K-平均算法
* 主成分分析（PCA）
* Apriori


### 半监督学习
#### 要点
* 可以处理部分标记的训练数据
* 大部分都是无监督算法和监督算法的结合

#### 算法
* 深度信念网络（DBN）


### 强化学习
#### 要点
* 可以自行学习什么是最好的策略




## 要素
* 模型
* 策略
* 算法


### 模型
* 监督学习中，模式就是要学习的**条件概率** 或 **决策函数**
* 假设空间：包含所有可能的条件概率分布或决策函数

#### 生成模型
##### 原理
* 由数据学习联合概率分布，求出条件概率分布作为预测模型

##### 算法
* 朴素贝叶斯
* 隐马尔科夫模型

##### 特点
* 学习收敛速度更快
* 可以使用在有隐变量的情况


#### 判别模型
##### 原理
* 由数据直接学习决策函数、条件概率分布

##### 算法
* k近邻法
* 感知机
* 支持向量机

##### 特点
* 学习准确率更高
* 可以简化学习问题


### 策略
* 学习的目标：从假设空间中选取最优模型

#### 损失函数（代价函数）
* 度量模型一次预测的好坏
* 记作：$L(Y, f(X))$

##### 分类
* 0-1损失
$$ 
L(Y,f(X)) = \begin{cases}
        1, & Y \ne f(X) \\
        0, & Y = f(X)
    \end{cases}
$$

* 平方损失
$$  L(Y, f(X)) = (Y - f(X))^2 $$

* 绝对损失
$$  L(Y, f(X)) = || Y - f(X) || $$

* 对数损失
$$ L(Y, P(Y|X)) = - log P(Y|X) $$


#### 风险函数
* 度量模型平均意义下的预测好坏
* 是损失函数的期望风险
* 记作：$R_{exp}(f)$
* 是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失
* 问题：模型的联合分布是未知


#### 经验风险
* 是模型关于训练样本的平均损失
* 根据大数定律，当样本容量足够大，经验风险趋向等于期望风险
* 由于现实中样本有限，所以需要对经验风险进行校正
    * 经验风险最小化
    * 结构风险最小化

##### 公式
$$ R_{emp}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) $$

##### 经验风险最小化
* 经验风险最小的模型就是最优的模型
$$
\min_{f \in F}  \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i))
$$


##### 结构风险最小化
* 为了防止过拟合而提出的策略
* 等价于正则化，在经验风险上加上表示模型复杂度的正则化项
$$
\frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) + \lambda J(f)
$$




## 度量指标

### 分类准确率
#### 混淆矩阵
##### 定义
* 实际值和预测值构成的矩阵

##### 概念
* 正例：预测值是要找的目标
* 负例：预测值不是要找的目标

##### 值
* TP（True Positive）：预测正确，预测值为正例
* TN （True Negative）：预测正确，预测值是负例
* FP （False Positive）：预测错误，将负例预测成正例
* FN （False Negative）: 预测错误，将正例预测成负例（遗漏了）

#### 准确率
* 定义：预测正确的样本占总体的比例
* 公式：$ accuracy = \frac { TP + TN } { TP + TN + FP + FN } $

#### 精确率（查准率）
* 定义：预测为正例中实际正例的比例
* 公式：$ precision = \frac { TP } { TP + FP } $

#### 召回率（查全率）
* 定义：正例中有多少被预测到了
* 公式：$ recall = \frac { TP } { TP + FN } $

#### 特异性
* 公式：$ specificity = \frac { TN } { FP + TN } $

#### 1-特异性
* 定义：错误识别的负例占所有负例的比例
* 公式：$ FPR = \frac { FP } { FP + TN } $

#### 灵敏度
* 定义：正确识别的正例占所有正例的比例
* 公式：$ TPR = \frac { TP } { TP + FN } $

#### F1（调和平均数）
##### 原因
* 精确率和召回率是一对矛盾的度量
* F1用于评估整体性能

##### 公式
$$
F1 =  \frac { 2 * precision * recall } { precision + recall }
$$

##### 值
* 范围：0 -- 1

#### Fb（加权调和平均数）
* F1的一般形式
* 作用：可以设置出对精确率和召回率的不同偏好
* 公式  $ \frac{1}{F_{\beta} } = \frac{1}{1 + \beta^2} 
         \ast  ( \frac{1}{P} + \frac{\beta^2}{R}  ) $


#### 全局F1
##### 作用
* 对多个混淆矩阵进行全局评估

##### 例子
* 多个二分类混淆矩阵
* 多分类，两两类别组合生成的混淆矩阵
    * 方法：将一个类别设置为True, 其他类别设置为False

##### 宏F1
###### 做法
1. 对各个混淆矩阵计算 精确率 和 召回率
2. 计算一个平均的 精确率和召回率
3. 计算出F1值

##### 微F1
###### 做法：
1. 对各个混淆矩阵进行平均，得到TP, FP, TN, FN
2. 计算出 精确率 和 召回率
3. 计算出F1值


### 排序能力
#### AUC
##### 定义
* ROC曲线下的面积

##### 含义
* 模型把用户关心的那一类样本排在其他样本前面的概率

##### 作用
* 度量一般情况下，学习器泛化性能的好坏
* 原因：分类相当于对排序数据的截断
    * 学习器输出一个实值、概率作为预测
    * 预测值与一个分类阀值进行比较
    * 大于阀值的为正例、否则为负例

##### 值
* 范围：0 --- 1
    * 1 排序完全正确
    * 0.5 排序是随机的（最差的结果）
    * 0 排序的顺序完全错误

##### ROC（受试者工作特征）
* 绘制
    * 将TPR(真正例率)作为纵轴
    * 将FPR(假正例率)作为横轴


### 评分准确度（回归问题）
#### RMSE（均方根误差）
##### 作用
* 检测评分准确度

##### 定义
* 计算预测值和真实值之间误差平方的均值

##### 公式
$$ 
RMSE = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (f_i - y_i)^2  } 
$$

##### 特点
* 对特大，特小的误差反映非常敏感

#### MedianAE（中位数绝对误差）
##### 定义
* 计算预测值和真实值绝对差值的中位值

##### 公式
$$ 
MedAE(f, y) = median(| y_1 - f_1|, ... , | y_n - f_n |)
$$

#### R平方（判定系数）
##### 作用
* 用于度量直线的拟合效果

##### 含义
* 拟合出的直线能在多大程度上解释实际发生的变异

##### 公式
$$ 
R^2 = 1 - \frac{ \sum_{i=1}^{n} (y_i - f_i)^2 }
           { \sum_{i=1}^{n} (y_i - \bar{y}_i)^2 }
$$
$$
\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i
$$

**说明**
* f 为预测值
* y 为真实值

##### 值
* 范围 0 -- 1
* 0表示拟合非常差，没有捕获到数据中的任何变动
* 1表示拟合分成好，捕获了数据中的所有变动



### 轮廓系数
#### 目的
* 评价聚类效果好坏

#### 样本的轮廓系数
* 公式：$ s(i) = \frac { b(i) - a(i) } { max (a(i), b(i)) } $
* a(i) 为样本i的簇内不相似度：样本到同簇其他样本的平均距离
* b(i) 为样本i的簇间不相似度：样本到其他簇的所有样本的平均距离

##### 值
* 范围：-1 --- 1
* 1 表示聚类合理
* -1 表示聚类不合理
* 0表示在两个簇的边界上

#### 算法结果的轮廓系数
* 定义：所有样本轮廓系数的均值




## 模型评估
* 目的：评估模型的泛化误差

### 评估方法
#### 数据分离
* 将数据分成训练数据和测试数据
* 训练数据用于训练算法
* 测试数据用于评估算法

#### k折交叉验证
* 评估机器学习算法的黄金准则

##### 原理
* 将数据分成k个子集
* 一个子集作为测试集，其他作为训练集

##### 优点
* 用数据的不同部分来训练模型
* 在相同的测试集上度量性能

##### 步骤
1. 将数据随机划分成k个部分
2. 保留一个部分作为测试集
3. 使用剩余部分训练模型，并在测试集上度量模型性能
4. 将步骤2，3重复k次，轮流使用一个部分做测试集
5. 将多个模型指标的平均值作为最终指标


### 评估步骤
1. 将数据分成训练集，测试集
2. 在训练集上使用交叉验证，来选择模型和确定超参数
3. 使用训练集对选定的模型和确定的超参数，进行最终训练
4. 使用测试集来测量泛化误差




## 多分类学习

### 思路
* 拆解法，将任务拆为若干个二分类任务

### 步骤
1. 将问题拆分为多个二分类任务
2. 对每个二分类任务，训练一个分类器
3. 预测时，对分类器结果进行集成，获取最终的多分类结果

### 拆分策略
#### OvO（一对一）
* 将N个类别两两配对（一个类别做正例，一个类别做反例）
* 生成 N(N - 1)/2 个二分类器
* 预测时
    * 样本提交给所有二分类器
    * 选择预测的最多的类别作为最终结果

#### OvR（一对其余）
* 将一个类别作为正例，其余类型为反例
* 生成 N 个二分类任务
* 预测时
    * 样本提交给所有二分类器
    * 只有一个分类器预测为正，选择该分类器类别作为最终结果
    * 多个分类器预测为正，选择置信度最大的类别作为最终结果

#### MvM（多对多）
* 每次将若干类别作为正例，若干其他类别作为反例
* 使用ECOC（纠错输出码）来构造正、反例

### ECOC
#### 概述
* 将编码的思想引入类别拆分
* 在解码阶段会有一定的容错性

#### 步骤
##### 编码
* 对N个类别进行M次划分
* 每次划分将一部分类别作为正例，一部分类别作为反例
* 训练出M个二分类器

##### 解码
* M个分类器对样本进行测试
* 将预测结果组成一个编码
* 将该预测编码与每个类别的编码进行比较
* 将编码距离最小的类别作为最终结果

#### 编码矩阵
* 二元码：正类、反类
* 三元码：正类、反类、停用类

##### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201217162502.png)

* C为类别，f为分类器
* +1为正类、-1为反类，0为停用类





## 类别不平衡

### 定义
* 分类任务中，不同类别的训练样本数差别很大

### 策略
#### 欠采样
##### 定义
* 去除一些多数类中的样本，使得不同类别的样本数量接近

##### 随机采样
* 方法：从多数类中随机选择一些样本，组成新的样本
* 缺点
    * 造成一些信息缺失

##### EasyEnsemble
* 步骤
    1. 从多数类中有放回的随机采样n次，获得n个新样本集
    2. 将新样本与少数类样本合并训练出模型，得到n个模型
    3. 最终模型结果是这n个模型的平均值


#### 过采样
##### 定义
* 增加一些少数类样本，使不同类别的样本数量接近

##### SMOTE（合成少数类过采样）
* 思想
    * 对每个样本x，从它的最近邻中随机选择一个样本y
    * 在 x 和 y 之间的连线上随机选择一个点作为新合成的样本






## 拟合问题

### 偏差-方差权衡
* 偏差：离正确值的距离，即预测的整体效果有多好
* 方差：预测的分散程度
* 误差：我们的目标是减少误差
    * 公式：误差 = 偏差 平方 + 方差

### 模型问题
* 过于简单的模型会导致低方差、高偏差
* 过于复杂的模型会导致高方差、低偏差

### 防止过拟合
#### 定义
* 随着模型复杂程度提升，训练集效果越来越好，但是测试集效果越来越差

#### 正则化
##### 思想
* 给目标函数增加惩罚项，来惩罚数值较大的权重参数，使其对结果的影响小一点

##### L1正则化
* 方法：给目标函数增加 所有特征系数的平方和
* 效果：对特征系数减去一个固定值，容易产生系数为0的情况
* 用途：更适合于特征选择

##### L2正则化
* 方法：给目标函数增加 所有特征系数的平方和
* 效果：对特征系数进行一个比例的缩放，让系数趋向变小
* 用途：更适合于防止模型过拟合










## 算法调参（优化超参数）

### 目标
* 模型在训练集上的准确度和防止过拟合能力的大和谐

### 方法

#### 网格搜索优化
* 原理：遍历已定义参数的列表来评估算法参数，从而找到最优参数

#### 随机搜索优化
* 原理：通过固定次数的迭代，采用随机采样分布的方式搜索参数










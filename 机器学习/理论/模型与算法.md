[TOC]

# 模型与算法

## 概述

### 经典算法
* k最近邻（KNN）
* 决策树

### 概率图算法
* 隐马尔可夫模型（HMM）

### 回归算法
* 线性回归

#### 思路
* 用观测值拟合一条曲线、函数
* 用拟合出的曲线、函数去预测未知值

### 分类算法
* 感知机
* 逻辑回归
* 朴素贝叶斯

### 降维算法
* 主成分分析（PCA）
* 线性判别分析（LDA）

#### 作用
* 使数据更容易查看、分类
* 有利于数据压缩

#### 要点
* 降维时要最大限度地保留原来的方差

### 聚类算法
* k均值（K-means）
* DBSCAN

#### 特点
* 解决问题的效果不如有监督算法
* 无监督导致对结果的评估比较困难
* 不同的算法得到的结果差异比较大
* 同一算法不同参数得到的结果差异也会比较大





## k最近邻（KNN）

### 概述
* 一种监督式学习算法

### 优点
* 思想简单，也用于回归和分类
* 用于非线性分类
* 训练的时间复杂度比较低
* 对数据没有假设，对异常点不敏感

### 缺点
* 预测计算量大，尤其特征数非常多的时候
* 训练是需要大量内存
* 样本不平衡时，对稀有类型的预测准确率低
* 可解释性不强

### 适用情况
* 样本容量比较大的类域的自动分类

### 要点

#### k值选择

##### 方法
* 选择一个较小的值，通过交叉验证选择一个合适的值

##### 值小
* 训练误差小，泛化误差大
* 模型整体变复杂，容易发生过拟合

##### 值大
* 泛化误差小，训练误差大
* 模型整体变简单，容易预测错误

#### 距离度量
* 欧式距离（最常用）
* 曼哈顿距离
* 闵可夫斯基距离（Minkowski）

#### 决策规则
* 回归：平均法，输出最近的k个样本的平均值
* 分类：多数表决法，选最近的k个样本数量最多的那个类别

### 实现方案

#### KD树

##### 原理
* 通过建立KD树，来减少无效的最近邻搜索

##### 步骤
1. 建树
1. 搜索最近邻
1. 预测

#### 球树（BallTree）
* 进一步优化KD树的搜索效率


### 扩展
* 限定半径最近邻：解决样本中某类别的样本非常少的情况
* 质心算法：通常用于文本分类












## 主成分分析（PCA）

### 概述
* 一种非监督学习算法
* 假设数据符合高斯分布
* 选择样本投影具有最大方差的方向（分类信息依赖于方差）

### 思想
* 找出数据里最主要的方面，用最主要方面来代替原始数据

### 降维标准
* 基于最小投影距离：样本点到超平面的距离足够近
* 基于最大投影方差：样本点在超平面上的投影尽可能的分开

### 主成分
* 定义：样本集的**协方差矩阵**的前n个**特征值**对应的**特征向量矩阵**

### 步骤
1. 对样本进行中心化
2. 计算样本的协方差矩阵
3. 对矩阵进行特征值分解
4. 取出最大的 n 个特征值对应的特征向量
5. 将所有n个特征向量标准化，生成特征向量矩阵
6. 使用该矩阵对每个样本进行转化，生成新样本

### 优点
* 只需要使用方差信息，不受数据集以外的因素影响
* 各主成分之间正交，可以消除原数据之间相互影响的因素
* 计算简单，主要使用特征值分解



## 线性判别分析（LDA）

### 概述
* 一种监督学习算法
* 假设数据符合高斯分布
* 选择分类性能最好的投影方向（分类信息依赖于均值）

### 思想
* 使投影后的类内方差最小，类间方差最大
* 将数据在低维度上进行投影
* 希望同一种类别数据的投影点尽可能的接近
* 希望不同类别数据的类别中心尽可能的分离

### 步骤
1. 计算类内散度矩阵 Sw
2. 计算类间散度矩阵 Sb
3. 计算出投影矩阵 W
4. 对样本中的每个样本特征，转化为新的样本

### 缺点
* 不适合对非高斯分布样本进行降维
* 最多降维到 k - 1
* 在样本分类信息依赖方差而不是均值时，效果不好


## k均值（K-means）

### 特点
* 基于距离计算来聚类
* 基于数据本身的特性，将一组数据划分为多个簇
* 根据数据离哪个中心点最近来决定属于哪个簇

### 步骤

#### 划分
1. 随机选择k个中心点
2. 计算每个数据点到中心点的距离，分配给离其最近的中心点
3. 基于簇重新计算中心点，将中心点移动到簇中所有点的中心
4. 重复步骤2，3，直到中心点不再移动

#### 预测
1. 计算新数据点到每个簇中心点的距离
1. 分配给离数据点最近的簇

### 优点
* 快速、简单
* 效果通常还是不错的
* 可解释性比较强

### 缺点
* k值比较难确定
* 在球形簇上效果比较好，其他类型效果一般

### 注意点
* k的选择：从一个比较小的值开始，逐渐增加直到方差不会有大的改善
* 距离度量：使用欧式距离，余弦相似度
* 局部最小值：进行多次聚类，最后将结果平均
* 标记簇：需要研究数据，找出每个簇的意义
* 数据标准化
    * 一定要对数据进行缩放，以达到标准化
    * 在标准化的数据上效果最好



## DBSCAN

### 特点
* 一种基于密度的聚类算法
* 常用于异常检测

### 概念
* r-邻域：给定对象半径r内的邻域
* 核心点：r-邻域内的数据点
* 边界点：落在核心点邻域内的数据点
* 离群点：即不是核心点，也不是边界点

### 步骤
1. 随机选择一个数据点
2. 使用r半径画园
3. 凡是能被其及其下属圈到的数据点都属于同一类别
4. 若该类型已发展完成，就重复1-3步骤，直到所有数据点都处理过

### 优点
* 可以对任意形状的稠密度数据集进行聚类
* 适合于检测任务，寻找离群点
* 不需要指定类别数目

### 缺点
* 如果样本密度不均匀，效果比较差
* 半径选择比较难，导致的结果差异比较大    





## 推荐算法

### 基于内容

#### 原理
* 使用NLP技术来挖掘文本的特征信息
* 根据文本的特性来获得用户偏好，进行推荐

### 协同过滤

#### 基于用户

##### 原理
* 计算用户之间的相似度
* 找出相似用户喜欢的物品
* 对物品进行打分，推荐分数高的

#### 基于物品

##### 原理
* 计算物品之间的相似度
* 对物品进行打分，推荐分数高的

#### 基于模型 - 关联算法

##### 原理
* 通过物品数据挖掘频繁集
* 如果用户购买了频繁集中的部分物品，可以推荐其他物品

##### 算法
* Apriori
* FP Tree

#### 基于模型 - 聚类算法

##### 原理

###### 基于用户
1. 将用户聚类，分成不同的人群
2. 计算相同人群中评分最高的物品，推荐给用户

###### 基于物品
1. 将物品聚类，分成不同的类型
2. 将用户评分高的物品的相似同类物品，推荐给用户

##### 算法
* K-Means
* BIRCH

#### 基于模型 - 回归算法

##### 原理
* 通过回归模型来预测用户给某物品的评分

##### 算法
* Ridge回归
* 回归树
* 支持向量回归

#### 基于模型 - 矩阵分解
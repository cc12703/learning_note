

# 聚类算法

[TOC]

## 总体

### 概述
* 针对给定的样本，根据样本特征的相似度、距离，将其归并到若干个类
* 目的：发现数据特点、对数据进行预处理
* 属于无监督学习


### 基本概念
#### 相似度或距离
* 是聚类的核心概念
* 会直接影响聚类的结果

##### 类型
* 闵可夫斯基距离：值越大，相似度越小
* 马哈拉偌比距离：值越大，相似度越小
* 相关系数：值越接近1，越相似
* 夹角余弦：值越接近1，越相似

#### 类或簇
* 硬聚类：一个样本只能属于一个类
* 软聚类：一个样本可以属于多个类

##### 定义
* 集合G中任意两个样本 $x_i, x_j$
* 满足 $ d_{ij} \le T $  （$d_{ij}$为两个样本之间的距离）
* 则称G为一个类

##### 特征
* 类均值（类中心） $$ \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i $$
* 类直径：任意两个样本之间的最大距离 $$ D = \max_{x_i,x_j \in G} d_{ij} $$
* 类散布矩阵
* 类协方差矩阵



### 特点
* 解决问题的效果不如有监督算法
* 无监督导致对结果的评估比较困难
* 不同的算法得到的结果差异比较大
* 同一算法不同参数得到的结果差异也会比较大



### 性能度量
* 用于度量聚类结果的好坏

#### 外部指标
* 将聚类结果与某个’参考模型‘进行比较
* Jaccard系数
* FM指数 (FMI)
* Rand指数 (RI)

#### 内部指标
* 直接考察聚类结果
* DB指数（DBI）
* Dunn指数（DI）


### 算法分类
#### 原型聚类
##### 思路
* 假设聚类结构能通过一组原型刻画

##### 步骤
1. 对原型进行初始化
2. 对原型进行迭代更新

##### 算法
* k均值（k-means）
* 学习向量量化（LVQ）
* 高斯混合聚类

#### 密度聚类
##### 思路
* 假设聚类结构能通过样本分布的紧密程度确定

##### 步骤
1. 从样本密度的角度来考察样本之间的可连接性
1. 基于可连接性，对样本不断扩展

##### 算法
* DBSCAN

#### 层次聚类
##### 思路
* 在不同层次对数据集进行划分，从而形成树形的聚类结构

##### 策略
* 聚合：自低向上进行划分
* 分拆：自顶向下进行划分

##### 算法
* AGNES


## k均值（K-means）

### 特点
* 基于距离计算来聚类
* 基于数据本身的特性，将一组数据划分为多个簇
* 根据数据离哪个中心点最近来决定属于哪个簇

### 策略
* 最小化样本到其所属类中心之间的距离总和
$$
E = \sum_{i=1}^k \sum_{x \in C_i} || x - \mu_i ||^2
$$
说明
* k为类总数
* $C_i$为特定的某个类
* $\mu_i$为特定类的均值向量

### 步骤
#### 划分
1. 随机选择k个中心点
2. 计算每个数据点到中心点的距离，分配给离其最近的中心点
3. 基于簇重新计算中心点，将中心点移动到簇中所有点的中心
4. 重复步骤2，3，直到中心点不再移动

#### 预测
1. 计算新数据点到每个簇中心点的距离
1. 分配给离数据点最近的簇

### 优点
* 快速、简单
* 效果通常还是不错的
* 可解释性比较强

### 缺点
* k值比较难确定
* 在球形簇上效果比较好，其他类型效果一般

### 注意点
* k的选择：从一个比较小的值开始，逐渐增加直到方差不会有大的改善
* 距离度量：使用欧式距离，余弦相似度
* 局部最小值：进行多次聚类，最后将结果平均
* 标记簇：需要研究数据，找出每个簇的意义
* 数据标准化
    * 一定要对数据进行缩放，以达到标准化
    * 在标准化的数据上效果最好




## DBSCAN

### 特点
* 一种基于密度的聚类算法
* 常用于异常检测

### 概念
* r-邻域：给定对象半径r内的邻域
* 核心点：r-邻域内的数据点
* 边界点：落在核心点邻域内的数据点
* 离群点：即不是核心点，也不是边界点

### 步骤
1. 随机选择一个数据点
2. 使用r半径画园
3. 凡是能被其及其下属圈到的数据点都属于同一类别
4. 若该类型已发展完成，就重复1-3步骤，直到所有数据点都处理过

### 优点
* 可以对任意形状的稠密度数据集进行聚类
* 适合于检测任务，寻找离群点
* 不需要指定类别数目

### 缺点
* 如果样本密度不均匀，效果比较差
* 半径选择比较难，导致的结果差异比较大  
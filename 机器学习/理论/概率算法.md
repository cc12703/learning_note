

# 概率算法

[TOC]


## 概述

### 概率模型
#### 功能
* 提供了一种描述框架，将学习任务归结于计算概率分布
* 核心：如果基于可观测变量推断出未知变量的条件分布

#### 分类
##### 生成式模型
* 直接对联合概率分布进行建模
* 生成非常全的信息
* 对数据量要求比较大

图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210203191244.png)


##### 判别式模型
* 直接对条件概率分布进行建模
* 生成总体判别边界
* 对数据量要求比较少

图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210203191445.png)



### 概率图模型
#### 定义
* 使用图来表示概率分布
* $G = (V, E)$  $V$为结点集合， $E$为边集合

#### 分类
* 有向无环图（贝叶斯网）：代表算法有HMM
* 无向图（马尔可夫网）：代表算法有CRF


#### 无向图模型
##### 特点
* 易于因子分解：联合概率分布等于最大团上的随机变量函数的乘积形式

##### 最大团
* 团：$G$中的一个子集，其中任何两个结点均有边连接
* 最大团：该团无法再加入一个结点使其变的更大

##### 公式
$$ P(Y) = \frac{1}{Z} \prod_C \Psi_C(Y_C) $$
$$ Z = \sum_Y \prod_C \Psi_C(Y_C) $$
说明
* $Z$为规范化因子
* $C$为最大团
* $Y_C$为最大团对应的随机变量
* $\Psi_C(Y_C)$为势函数，通常定义为指数函数





## 朴素贝叶斯

### 要点
* 使用贝叶斯公式
* 假设样本特征之间是独立的

### 模型
#### 贝叶斯公式
$$
P(Y_k|X)= \frac{ P(X|Y_k)P(Y_k) }
               { \sum_k P(X| Y=Y_k)P(Y_k) } 
$$

#### 模型公式
$$
C_{result} =  \underbrace{argmax}_{C_k}
              P(Y = C_k)
              \prod_{j=1}^{n} P( X_j = X_{j}^{(test)} | Y = C_k)
$$
说明
* n 样本特征个数
* C 类别值，一共k个

### 步骤
1. 计算Y的先验概率
2. 计算第k个类别下的第j个特征的条件概率
3. 通过模型公式，计算所有的k个条件概率
4. 选择概率最大的作为预测类型

### 优点
* 小规模数据的表现比较好
* 能处理多分类
* 适合增量训练
* 对缺失数据不敏感

### 缺点
* 属性数较多、属性间相关性较大时，分类效果差
* 需要知道先验概率
* 对输入数据的表达形式很敏感

### 改进
* 如果有概率为零的情况，需要进行拉普拉斯平滑处理




## 条件随机场（CRF）

### 总体
#### 概述
* 是判别式的无向图模型


#### 用途
* 词性标注


#### 概念
* 随机场：由若干个位置组成，每个位置的值由随机分布获取
* 马尔可夫随机场：场中某一位置的值，仅与相邻位置的值有关
* 条件随机场：给定随机变量$X$的条件下，随机变量$Y$的马尔可夫随机场
* 线性条件随机场：$X$和$Y$有相同的结构，都为线性链表示的随机变量序列


### 模型
图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210202181348.png)

#### 参数化形式
$$ 
P(y|x) = \frac{1}{Z(x)} 
        exp \left( \sum_{i,k} \lambda_k t_k(y_{i-1}, y_i, x, i)
        + \sum_{i,l} \mu_l s_l(y_i, x, i) \right)
$$
$$
    Z(x) = \sum_y 
        exp \left(\sum_{i,k} \lambda_k t_k(y_{i-1}, y_i, x, i)
        + \sum_{i,l} \mu_l s_l(y_i, x, i) \right)
$$
说明
* $i$为当前节点在序列中的位置
* $s_l(y_i, x, i)$为节点特征函数, $\mu_l$为对应的权重系数
* $t_k(y_{i-1}, y_i, x, i)$为边特征函数，$\lambda_k$为对应的权重系数
* 特征函数取值为 1 或 0

#### 向量形式
* 将两类特征函数合并成一个特征函数向量
* 将两类权重系数合并成一个全新系数向量
$$
    P_{\omega}(y|x) = \frac{ exp(\omega \bullet F(y,x)) } 
                           { \sum_y exp(\omega \bullet F(y,x)) }
$$

$ \omega = (\omega_1, \omega_2, ..., \omega_k)^T $

$ F(y,x) = (f_1(y,x), f_2(y,x), ..., f_k(y,x))^T $
$ f_k(y, x) = \sum_{i=1}^{n} f_k(y_{i-1}, y_i, x, i) $


#### 矩阵形式
* 定义一个$m \times m$的矩阵$M$，$m$为$y$所有可能状态的个数
$$
P_{\omega}(y|x) = \frac{1}{Z_{\omega}(x)} 
            \prod_{i=1}^{n+1} M_i(y_{i-1},y_i | x)
$$
$$ M_i(y_{i-1},y_i | x) = exp( \sum_{k=1}^K \omega_k f_k(y_{i-1}, y_i, x, i)) $$







## 隐马尔可夫模型（HMM）

### 总体
#### 概述
* 是生成式的有向图模型
* 是结构最简单的动态贝叶斯网

#### 用途
* 时序数据建模
* 语言识别
* 自然语言处理


### 模型
#### 假设
* 一次马尔科夫链：任意时刻的隐藏状态只依赖其前一个隐藏状态
* 观测独立性：任意时刻观测状态只依赖于当前时刻的隐藏状态

#### 简化结构
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201230194413.png)

#### 定义
$ Q = \{ q_1, q_2, ..., q_N \} $ 所有隐藏状态的集合，$N$为个数
$ V = \{ v_1, v_2, ..., v_M \} $ 所有观测状态的集合，$M$为个数
$ I = \{ i_1, i_2, ..., i_T \} $ 状态序列，$T$为长度
$ O = \{ o_1, o_2, ..., o_T \} $ 观测序列，$T$为长度

#### 模型公式
$ \lambda = (A, B, \Pi) $

##### 状态转移矩阵
* 模型在各个隐藏状态间转移的概率

$$ A = \left [ a_{ij} \right ]_{N \times N} $$
$$ a_{ij} = P( i_{t+1} = q_j | i_{t} = q_i) $$
说明
* $a_{ij}$表示从t时刻的隐藏状态$q_i$到t+1时刻的隐藏状态$q_j$的概率

##### 观测生成矩阵
* 模型根据当前状态获得各个观测值的概率

$$ B = \left [ b_j(k) \right ]_{N \times M} $$
$$ b_j(k) = P( o_t = v_k | i_t = q_j)  $$
说明
* $b_j(k)$ 表示在t时刻，隐藏状态$q_j$生成观测状态$v_k$的概率

##### 初始状态
* 模型在初始时各个隐藏状态出现的概率

$$ \Pi = \left [ \pi(i) \right ]_N $$
$$ \pi(i) = P(i_1 = q_i)  $$
说明
* $\pi(i)$表示在初始时刻，隐藏状态$q_i$的出现概率


### 三个问题
#### 评估观测序列概率
* 定义：给定模型$\lambda$和观测序列$O$，计算观测序列出现的概率$P(O|\lambda)$
* 算法：前向算法、后向算法
* 用途：根据以往的观测序列来推测当前时刻最有可能的观测值

#### 预测问题
* 定义：给定模型$\lambda$和观测序列$O$，求出最有可能的状态序列
* 算法：维特比算法
* 用途：像语言识别，观测值为语言信号，隐藏状态为文字

#### 模型参数学习
* 定义：给定观测序列$O$，估计模型$\lambda$的参数，使得概率$P(O|\lambda)$最大
* 算法：EM算法

### 前向算法
#### 概述
* 属于动态规划算法：通过局部状态递推公式来求解

#### 前向概率
##### 定义
* 在时刻t隐藏状态为$q_i$的条件下，观测状态的序列为$o_1,o_2,...,o_t$的概率
* $ \alpha_t(i) = P(o_1, o_2, ..., o_t | i_t = q_i, \lambda) $

##### 公式
$$ 
\alpha_{t+1}(i) = \left [ \sum_{j=1}^{N} \alpha_t(j) a_{ji} \right ] b_t(o_{t+1}) 
$$
说明
* 基于时刻t的各个隐藏状态的前向概率，乘以状态转移概率。最后在乘以时刻t+1的观测生成概率

#### 流程
1. 计算开始时刻(t=1)的各个隐藏状态的前向概率
    $$ a1(i) = \pi_i b_i(o_1) , i = 1,2,...,N $$
2. 计算时刻2,3,...,T的前向概率（使用递推公式）
3. 计算最终结果
    $$ P(O|\lambda) = \sum_{i=1}^{N} \alpha_T(N) $$


### 后向算法
#### 概述
* 属于动态规划算法：通过局部状态递推公式来求解

#### 后向概率
##### 定义
* 在时刻t隐藏状态为$q_i$的条件下，观测状态的序列为$o_{t+1},o_{t+2},...,o_T$的概率
* $ \beta_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T | i_t = q_i, \lambda) $

##### 公式
$$
\beta_t(i) = \sum_{j=1}^{N} a_{ij} b_j(o_{t+1}) \beta_{t+1}(j)
$$

#### 流程
1. 初始化时刻T的各个隐藏状态的后向概率
    $$ \beta_T(i) = 1, i= 1,2,...,N $$
1. 计算时刻T-1, T-2, ..., 1时刻的后向概率（使用递推公式）
1. 计算最终结果
    $$ P(O|\lambda) = \sum_{i=1}^{N} \pi_i b_i(o_1) \beta_1(i) $$


### 维特比算法
#### 概述
* 通用算法
* 基于动态规划的求序列最短路径

#### 局部状态
* $\delta_t(i)$：在时刻$t$隐藏状态为$i$所有可能的状态转移路径中概率最大的值
* $\Psi_t(i)$：值为$\delta_t(i)$的转移路径中第$t-1$个节点的隐藏状态

$$
\delta_{t+1}(i) = (\max_{1\le j \le N} [\delta_t(j) a_{ji}]) 
                  b_i(o_{t+1})
$$
$$
\Psi_t(i) = arg \max_{1\le j \le N} [ \delta_{t-1}(j) a_{ji} ]
$$

#### 流程
1. 初始化局部状态
    $ \delta_1(i) = \pi_i b_i(o_1) , i = 1,2,...,N $
    $ \Psi_1(i) = 0 , i = 1,2,...,N $
1. 递推时刻$t=2, 3, ..., T$的局部状态 （使用递推公式）
1. 计算时刻T最大的$\delta_T(i)$：最有可能的隐藏状态出现的概率
1. 计算时刻T最大的$\Psi_t(i)$：最有可能的隐藏状态
1. 利用局部状态$\Psi_t(i)$，开始回溯
    $ i_t^* = \Psi_{t+1}(i_{t+1}^*)$
1. 获得隐藏状态序列 $ I^* = {i_1^*, i_2^*, ..., i_T^*} $


### EM算法

#### 状态概率
##### $\gamma_t(i)$
* 含义：给定模型$\lambda$，观测$O$，在时刻$t$隐藏状态为$q_i$的概率
* 定义：$ \gamma_t(t) = P(i_t = q_t | O,\lambda)$
* 公式
    $$ \gamma_t(t) = \frac {\alpha_t(i) \beta_t(i)} 
        {\sum_{j=1}^N \alpha_t(j) \beta_t(j)} 
    $$

##### $\xi_t(i,j)$
* 含义：给定模型$\lambda$，观测$O$，在时刻$t$处于$q_i$且在时刻$t+1$处于$q_j$的概率
* 定义：$ \xi_t(i,j) = P(i_t=q_i, i_{t+1}=q_j | O, \lambda) $
* 公式
    $$ \xi_t(i,j) = \frac {\alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j)}
        {\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j) }
    $$



#### 参数估计公式
##### 步骤
1. E步，求出$Q(\lambda, \bar{\lambda})$
1. M步，极大化$Q(\lambda, \bar{\lambda})$，求出估计公式


#### 流程
1. 随机初始化所有的 $\pi_i, a_{ij}, b_j(k)$
1. 对于每个样本，用于前向后向算法计算$\gamma_t(i), \xi_t(i,j)$
1. 使用估计公式，更新模型参数
1. 如果参数已收敛，则结束。否则进入步骤2，继续迭代






## 参考资源
* [隐马尔科夫模型HMM](https://www.cnblogs.com/pinard/p/6945257.html)

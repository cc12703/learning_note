
# 统计和概率

[TOC]



## 基础概念  

### 均值
 * 含义：平均数
 * 公式：样本总额 / 样本总数
 * 问题：受离群点的影响比较大

### 众数
 * 含义：数据集中最常见的值
 * 方法：找出现最频繁的数
 * 问题：不适合连续型数据


### 分位数
 * 定义：将数据划分为相等的若干份

#### 中位数
 * 含义：位于中间位置的值
 * 方法：先排序，后找中间点
 * 好处：受离群点的影响比较小

#### 四分位数
 * 含义：将数据分成四等分

#### 百分位数
##### 含义
 * 将数据分成100等分
 * 数据集中的xx%的数据都小于该值

##### 方法
 1. 先排序
 2. 后找xx%的数据都小于的值


### 方差
#### 含义
* 用于描述数据的分散程度，数据集的分布形状

#### 计算方法
 1. 计算数据集的均值
 1. 计算每个数据点和均值的差
 1. 计算差的平方（去除正负号的影响、放大离群点的作用）
 1. 计算差平方的均值

#### 标准差
 * 定义：方差的平方根
 * 作用：用于判断数据是否是离群点（和均值有多少个标准差）

#### 总体方差
##### 公式
 * $ \sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (Y_i - \mu)^2 $
 * $ \mu $ 总体里面所有数据的平均值
 * N 总体里面数据的个数

#### 样本方差
##### 作用
* 用于估计总体方差

##### 公式
* $ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (Y_i - \bar{Y} )^2 $
* $ \bar{Y} $ 样本中所有数据的平均值
* n 样本中数据的个数



### 协方差
#### 含义
* 表示两个属性之间的依赖程度，值越大依赖程度越大

#### 公式
* $ Cov(X, Y) = \frac{ \sum_{i=1}^{n} (X_i-\bar{X})(Y_i-\bar{Y}) }{ n - 1} $
* $\bar{X}$ 表示X的均值
* $\bar{Y}$ 表示Y的均值

#### 计算方法
1. 将数据看作两个高维向量
2. 计算出与均值之间的差异向量
3. 计算两个向量的点积
4. 点积值除以样本大小

#### 问题
* 难以进行量化解释



### 相关系数
#### 作用
* 对协方差的值进行归一化

#### 含义
* -1表示完全负相关
* 0表示不相关
* 1表示完全正相关

#### 公式
* $ r(X, Y) = \frac{ Cov(X,Y) }{ \sigma_X \sigma_Y } $
* Cov表示协方差， $\sigma$表示标准差



### 概率函数
#### 概率密度函数
* 用于连续型数据
* 含义：表示一个特定范围的值发生的概率
* 作用：给出了数据点落在一个给定范围内的概率
* 图形：一条连续的曲线

#### 矩
##### 含义
* 描述概率密度函数形状的数量指标

##### 类型
* 一阶矩：均值
* 二阶矩：方差
* 三阶矩：偏度
    * 含义：描述一个分布的倾斜程度，即数据的尾部偏向哪一侧
    * 曲线的长尾在左侧就为负偏，曲线的长尾在右侧就为正偏
    * 值：越接近0，表示没有偏
* 四阶矩：峰度
    * 含义：描述一个分布尾部的肥厚程度和顶部的尖锐程度，即从两侧向中间被挤压的程度
    * 值：越接近0，表示顶部越尖锐

#### 概率质量函数
* 用于离散型数据
* 含义：某个离散值出现在数据集中的概率
* 图形：直方图




### 贝叶斯定理
#### 公式
* $ P(A|B) = \frac{ P(B|A) P(A) }{ P(B) } $
* 可以由条件概率公式推出
* P(A|B) 称为 后验概率
* P(A)和P(B) 称为 先验概率
* P(B|A) 称为 可能性

#### 意义
* 在事件A已发发生的条件下，可以来寻找导致A发生的各种原因B的概率
* 公式 $ P(B_i|A) = \frac{ P(B_i)P(A|B_i) }{ \sum_{j=1}^{n} P(B_j)P(A|B_j) } $

#### 要点
* **给定A时B的概率**和**给定B时A的概率**不是一回事
* 在**给定A时B的概率**与**A，B的基础概率**有非常大的关系






## 常用数据分布

### 伯努利分布(0-1分布)
#### 要点
* 关于布尔变量（0，1）的概率分布

#### 公式
##### 概率质量函数
$$
P(x | \mu ) = {\mu}^x (1 - \mu)^{1-x}
$$
说明
* x只能取0或1
* $\mu$为 x == 1时的概率

##### 期望
$$
E[x] = \mu
$$

##### 方差
$$
var[x] = \mu (1 - \mu)
$$



### 二项分布
#### 要点
* 描述N次独立的伯努利实验中m次成功的概率
* 离散型分布

#### 公式
##### 概率质量函数
$$
P(m | N,\mu ) = \binom{N}{m} {\mu}^m (1 - \mu)^{N-m}
$$
说明
* $\mu$为实验成功的概率

##### 期望
$$
E[x] = N \mu
$$

##### 方差
$$
var[x] = N \mu (1 - \mu)
$$



### 均匀分布
#### 特点
* 定义在指定区间上的连续概率分布
* 概率是一条水平固定的直线

#### 公式
##### 概率密度函数
$$
p(x | a,b) = \frac{1}{b - a} 
$$

##### 期望
$$
E[x] = \frac{a+b}{2}
$$

##### 方差
$$
var[x] = \frac{(b - a)^2}{12} 
$$

#### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201117101904.png)




### 指数分布
* 特征：值都集中在0附近，远离0时值出现的概率会急剧下降



### 正态分布（高斯分布）
#### 特点
* 生活中最常见的一种分布
* 曲线：两头低，中间高，左右对称

#### 公式
##### 概率密度函数
$$
p(x| \mu,\sigma^2 ) = \frac{1}{\sqrt{2\pi\sigma ^2}} 
           exp \left \{  -\frac{(x-\mu)^2}{2\sigma^2}  \right \} 
$$
说明
* $\mu$为期望，决定了分布的位置
* $\sigma^2$为方差，决定了分布的幅度

#### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201110110443.png)

#### 图示-不同参数
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201110105132.png)






## 估计理论

### 背景（推断统计）
* 无法获取所有数据
* 只能采集一部分数据
* 通过这些数据推断所有数据的情况

### 问题设定
* 假定实际观测与真实分布相关，试图根据观测值来推测真实分布
* 估计值是随机的
* 估计方式不同，得到的估计值也不同

#### 问题分类
* 非参数统计问题：其具体分布不确定的问题
* 参数统计问题：期望值、方差不确定，分布遵从正态分布的问题


### 方法-最小方差无偏估计
#### 思想
* 通过增加条件来排除无效估计量

#### 无偏性
* 一种常见的筛选条件
* 估计值的期望始终与正确答案一致

#### 条件
$$
E[\hat{\theta}(X)] = \theta 
$$
说明
* $\theta$为正确值
* $\hat{\theta}$为估计值
* 对任意$\theta$始终成立


### 方法-最大似然估计
#### 思想
* 减弱最优定义，使似然函数值最大即为最优

#### 优点
* 可以通过简单计算求得
* 对参数进行变换后，估计结果依然符号要求
* 一致性和渐进有效性可以通过恰当的假设条件得到





## 杂

### 蒙特卡罗法
#### 概述
* 是一种统计模拟方法
* 通过对概率模型的随机抽样，进行近似数据计算
* 核心是**随机抽样**

#### 用法
1. 构造一个合适的概率模型
1. 对模型进行大量的采样和统计实验（模型的某些统计参量正好是待求问题的解）
1. 把这个参量的值统计出来即可


#### 例子
##### 估计圆周率的值
1. 绘制一个单位长度的正方形，并绘制四分之一圆
1. 在正方形上随机采样尽可能多的点
1. 由公式得出：$$\pi = \frac{4N}{3000}$$ ($N$为圆内部的点，$n$为一共采样的点)

图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/mc-example-one.jpg)

##### 估计任意积分值
1. 在矩形内部，产生大量的随机点
1. 计算出有多少点落在阴影部分，条件为$ y_i < f(x_i) $
1. 由公式得出：$$ \frac{N_{阴影}}{N_{total}} = \frac{S_{积分}}{S_{矩形}} $$

图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/mc-example-two.jpg)


#### 思想
$$
\int_{a}^{b} f(x) dx = E_{x \sim p(x)} [ \frac{f(x)}{p(x)} ]
$$
$$
\frac{1}{n} \sum_{i=1}^n \frac{f(x_i)}{p(x_i)} 
\to E_{x \sim p(x)} [ \frac{f(x)}{p(x)} ]
$$
说明：
* $f(x)$很难求出具体表达式
* $p(x)$为概率分布
注意：
* $n$个点要**按照$p(x)$来采样**，$n$越大，越精确


#### 拒绝-接受采样
* 是一种随机抽象方法
* 适用于概率分布极度复杂且不规则的情况

##### 思想
* 由于$p(x)$无法直接采样
* 找一个可以直接采样的概率分布作为媒介（称为 建议分布）

##### 步骤
1. 定义一个建议分布$q(x)$和常量$c$
    * 满足 $p(x)$ 总在 $c q(x)$的下方
1. 对$q(x)$进行采样，得到采样点$x^*$
1. 对均匀分布$(0, cq(x^*))$进行采样，得到采样值$u$
1. 如果采样值$u$满足以下公式，就接受，否则就拒绝
    $$  u \le \frac{p(x^*)}{ c q(x^*) }$$


##### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20210115192259.png)



### 马尔可夫链
####  概述
* 描述随时间在状态之间转移的模型
* 假设未来的转移状态只依赖于现在的状态

#### 定义
* 一个随机变量序列 $ X = \{ X_0, X_1, ..., X_t \} $ , $t$表示时刻
* 满足马尔可夫性：$ P(X_t | X_{t-1},X_{t-2},...,X_0) = P(X_t | X_{t-1}) $
* 条件概率分布$ P(X_t | X_{t-1}) $称为马尔可夫转移概率分布

#### 遍历定理
* 不可约、非周期且正常返的马尔可夫链，有唯一平稳分布存在
* 并且转移概率的极限分布是马尔可夫的平稳分布

##### 概念说明
* 不可约：每个状态都能去到
* 非周期：返回时间公约数是1
* 正常返：离开此状态有限步一定能回来。迟早会回来

##### 满足定理的含义
* 只有一个平稳分布，而且它就是转移概率的极限分布
* 从不同的起始点出发，都会收敛到同一平稳分布
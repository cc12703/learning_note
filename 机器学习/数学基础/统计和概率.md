
# 统计和概率

[TOC]

## 基础概念  

### 均值

 * 含义：平均数
 * 公式：样本总额 / 样本总数
 * 问题：受离群点的影响比较大

### 众数

 * 含义：数据集中最常见的值
 * 方法：找出现最频繁的数
 * 问题：不适合连续型数据

### 分位数

 * 定义：将数据划分为相等的若干份

#### 中位数

 * 含义：位于中间位置的值
 * 方法：先排序，后找中间点
 * 好处：受离群点的影响比较小

#### 四分位数

 * 含义：将数据分成四等分

#### 百分位数

##### 含义
 * 将数据分成100等分
 * 数据集中的xx%的数据都小于该值

##### 方法
 1. 先排序
 2. 后找xx%的数据都小于的值

### 方差

#### 含义
* 用于描述数据的分散程度，数据集的分布形状
                                                                                                                                                                                       
#### 计算方法
 1. 计算数据集的均值
 1. 计算每个数据点和均值的差
 1. 计算差的平方（去除正负号的影响、放大离群点的作用）
 1. 计算差平方的均值

#### 标准差
 * 定义：方差的平方根
 * 作用：用于判断数据是否是离群点（和均值有多少个标准差）

#### 总体方差

##### 公式
 * $ \sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (Y_i - \mu)^2 $
 * $ \mu $ 总体里面所有数据的平均值
 * N 总体里面数据的个数

#### 样本方差

##### 作用
* 用于估计总体方差

##### 公式
* $ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (Y_i - \bar{Y} )^2 $
* $ \bar{Y} $ 样本中所有数据的平均值
* n 样本中数据的个数


### 协方差

#### 含义
* 表示两个属性之间的依赖程度，值越大依赖程度越大

#### 公式
* $ Cov(X, Y) = \frac{ \sum_{i=1}^{n} (X_i-\bar{X})(Y_i-\bar{Y}) }{ n - 1} $
* $\bar{X}$ 表示X的均值
* $\bar{Y}$ 表示Y的均值

#### 计算方法
1. 将数据看作两个高维向量
2. 计算出与均值之间的差异向量
3. 计算两个向量的点积
4. 点积值除以样本大小

#### 问题
* 难以进行量化解释


### 相关系数

#### 作用
* 对协方差的值进行归一化

#### 含义
* -1表示完全负相关
* 0表示不相关
* 1表示完全正相关

#### 公式
* $ r(X, Y) = \frac{ Cov(X,Y) }{ \sigma_X \sigma_Y } $
* Cov表示协方差， $\sigma$表示标准差


### 概率函数

#### 概率密度函数
* 用于连续型数据
* 含义：表示一个特定范围的值发生的概率
* 作用：给出了数据点落在一个给定范围内的概率
* 图形：一条连续的曲线

#### 矩

##### 含义
* 描述概率密度函数形状的数量指标

##### 类型
* 一阶矩：均值
* 二阶矩：方差
* 三阶矩：偏度
    * 含义：描述一个分布的倾斜程度，即数据的尾部偏向哪一侧
    * 曲线的长尾在左侧就为负偏，曲线的长尾在右侧就为正偏
    * 值：越接近0，表示没有偏
* 四阶矩：峰度
    * 含义：描述一个分布尾部的肥厚程度和顶部的尖锐程度，即从两侧向中间被挤压的程度
    * 值：越接近0，表示顶部越尖锐

#### 概率质量函数
* 用于离散型数据
* 含义：某个离散值出现在数据集中的概率
* 图形：直方图


### 贝叶斯定理

#### 公式
* $ P(A|B) = \frac{ P(B|A) P(A) }{ P(B) } $
* 可以由条件概率公式推出
* P(A|B) 称为 后验概率
* P(A)和P(B) 称为 先验概率
* P(B|A) 称为 可能性

#### 意义
* 在事件A已发发生的条件下，可以来寻找导致A发生的各种原因B的概率
* 公式 $ P(B_i|A) = \frac{ P(B_i)P(A|B_i) }{ \sum_{j=1}^{n} P(B_j)P(A|B_j) } $

#### 要点
* **给定A时B的概率**和**给定B时A的概率**不是一回事
* 在**给定A时B的概率**与**A，B的基础概率**有非常大的关系


## 常用数据分布


### 伯努利分布(0-1分布)

#### 要点
* 关于布尔变量（0，1）的概率分布

#### 公式

**概率质量函数**
$$
P(x | \mu ) = {\mu}^x (1 - \mu)^{1-x}
$$

* x只能取0或1
* $\mu$为 x == 1时的概率

**期望**
$$
E[x] = \mu
$$

**方差**
$$
var[x] = \mu (1 - \mu)
$$

### 二项分布

#### 要点
* 描述N次独立的伯努利实验中m次成功的概率
* 离散型分布

#### 公式

**概率质量函数**
$$
P(m | N,\mu ) = \binom{N}{m} {\mu}^m (1 - \mu)^{N-m}
$$

* $\mu$为实验成功的概率

**期望**
$$
E[x] = N \mu
$$

**方差**
$$
var[x] = N \mu (1 - \mu)
$$





### 均匀分布

#### 特点
* 定义在指定区间上的连续概率分布
* 概率是一条水平固定的直线

#### 公式

**概率密度函数**
$$
p(x | a,b) = \frac{1}{b - a} 
$$

**期望**
$$
E[x] = \frac{a+b}{2}
$$

**方差**
$$
var[x] = \frac{(b - a)^2}{12} 
$$

#### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201117101904.png)




### 指数分布
* 特征：值都集中在0附近，远离0时值出现的概率会急剧下降



### 正态分布（高斯分布）

#### 特点
* 生活中最常见的一种分布
* 曲线：两头低，中间高，左右对称

#### 公式

**概率密度函数**
$$
p(x| \mu,\sigma^2 ) = \frac{1}{\sqrt{2\pi\sigma ^2}} 
           exp \left \{  -\frac{(x-\mu)^2}{2\sigma^2}  \right \} 
$$

* $\mu$为期望，决定了分布的位置
* $\sigma^2$为方差，决定了分布的幅度


#### 图示
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201110110443.png)


#### 图示-不同参数
![](https://gitee.com/cc12703/figurebed/raw/master/img/20201110105132.png)


## 估计理论

### 背景（推断统计）
* 无法获取所有数据
* 只能采集一部分数据
* 通过这些数据推断所有数据的情况

### 问题设定
* 假定实际观测与真实分布相关，试图根据观测值来推测真实分布
* 估计值是随机的
* 估计方式不同，得到的估计值也不同

#### 问题分类
* 非参数统计问题：其具体分布不确定的问题
* 参数统计问题：期望值、方差不确定，分布遵从正态分布的问题

### 方法-最小方差无偏估计

#### 思想
* 通过增加条件来排除无效估计量

#### 无偏性
* 一种常见的筛选条件
* 估计值的期望始终与正确答案一致

#### 条件
$$
E[\hat{\theta}(X)] = \theta 
$$

* $\theta$为正确值
* $\hat{\theta}$为估计值
* 对任意$\theta$始终成立

### 方法-最大似然估计

#### 思想
* 减弱最优定义，使似然函数值最大即为最优

#### 优点
* 可以通过简单计算求得
* 对参数进行变换后，估计结果依然符号要求
* 一致性和渐进有效性可以通过恰当的假设条件得到


## 检验理论 

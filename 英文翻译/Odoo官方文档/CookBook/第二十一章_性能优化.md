


# 第二十一章_性能优化

[TOC]


## 记录集的预取模式

### 概述
* 当从数据集中获取记录时，实际上就是对数据库发起一次查询
* 如果数据集中有多条记录，在其中读取记录会使系统变慢，因为会有多次SQL查询


### 如何操作
#### 例子1
##### 正确预取
* 示例代码
```python
def compute_method(self) :
    for rec in self:
        print(rec.name)
```
* 该方法是一个正常的计算方法，self表示有多条记录的记录集
* 当直接遍历记录集时，预取会正常工作

#### 例子2
##### 不正确预取
* 示例代码
```python
def some_action(self) :
    record_ids = []
    self.env.cr.execute("some query to fetch record id")
    for rec in self.env.cr.fetchall():
        record = self.env['res.partner'].browse(rec[0])
        print(record.name)
```
* 该方法使用browse方法来读取数据，在for循环中一个一个的读取记录
* 这时候并没有有效的使用预取，仍然会导致多次查询

##### 正确预取
* 示例代码
```python
def some_action(self):
    record_ids = []
    self.env.cr.execute("some query to fetch record id")
    record_ids = [ rec[0] for rec in self.env.cr.fetchall() ]

    recordset = self.env['res.partner'].browse(record_ids)
    for record_id in recordset:
        print(record.name)
```
* 通过给browse方法传入一个ID的列表，你可以创建一个有多条记录的记录集
* 在该记录集上执行操作，预取会正常工作
* 使用这种方法，你不会丢失预取特性，数据会在一个SQL查询中获取



### 工作原理
* 当在有多条记录的记录集中工作时，预取可以减少SQL查询的个数
    * 通过一次获取全部的数据来达到的
    * 通常情况下，预取会自动执行，但是在某些情况下会丢失该功能
    * 例如像以下代码的那样分隔记录
        ```python
        recs = [r for r in recordset r.id not in [1,2,4,10]]
        ```
* 正确的使用预取可以显著的提升ORM库的性能

#### 工作方式
* 当通过for循环遍历记录集时，并在第一次迭代中读取了一个字段的值，预取操作就会启动
* 预取操作会一次读取所有的记录
* 依赖的逻辑是：如果你在fo循环中读取字段了，你很有可能会继续读取下一条记录的数据
* 预取会一次读取所有记录并将其保存在缓存中，在循环的下一次迭代时，数据会直接从缓存获取

#### 例子
* 设想一个有10条记录的记录集
* 当你在循环的第一个迭代中读取记录的name字段时，预取会读取所有的10条记录
* 预取并不只读取name字段，而是会读取所有10条记录的所有字段
* 在循环的接下来的迭代中，数据会直接从缓存获取
* SQL查询次数会从10次下降到1次
* 代码
    ```python
    for record in recordset :  #记录集有10条记录
        record.name   #在首次迭代时，预取全部10条记录
        record.email  #email的数据将从缓存中获取
    ```
* 注意，预取获取所有的字段（除了*2many字段），会包括哪些在for循环中没有使用的字段
    * 因为相比于为每个字段执行一次查询，额外的列只会对性能有少许的影响


#### 注意
* 有时候，预取的字段会降低性能
* 这个时候，可以通过在上下文中将prefetch_fields设置为False来禁止预取
    ```python
    recordset.with_context(prefetch_fields=False)
    ```

#### 缓存
* 预取机制使用环境缓存来存储、检索记录值
    * 意味着，一旦从数据库中预取了记录，所有的字段的子操作将会使用系统缓存
* 可以通过env.cache属性来读取环境缓存
* 可以使用invalidate_cache()来无效掉缓存



### 更多
#### 拆分记录集
* 当你拆分记录集时，ORM库会使用新的预取上下文来生成一个新记录集
* 在该记录集上执行的操作只能预取各自独立的记录
* 如果你想预取所有的记录，需要将预取记录ID传给with_prefetch()方法
* 示例
    ```python
    recordset = ... #假设记录集有10条记录
    recordset1 = recordset[:5].with_prefetch(recordset._ids)
    recordset2l = recordset[5:].with_prefetch(recordset._ids)
    ```
* 这样预取上下文将不会限制在分离的记录集上
* 你也可以使用with_prefetch()来在多个记录集之间共享一个公共的上下文
    * 意味着：当你从一个记录中读取数据时，也会为其他记录集读取数据





## 内存缓存-ormcache

### 概述
* Odoo框架提供了ormcache装饰符来管理内存缓存


### 如何操作
#### 导入类
* ORM缓存的类位于/odoo/tools/cache.py
* 为了在任何文件中可以使用，需要进行导入
    ```python
    from odoo import tools
    ```

#### ormcache
##### 概述
* 这个装饰符是最简单，最常用的缓存装饰符
* 你需要传入方法的参数名字，作为输出依赖
* 示例
    ```python
    @tools.ormcache('mode')
    def fetch_mode_data(self, mode):
        # 一些计算
        return result
    ```

##### 运行方式
* 当第一次调用该方法时，该方法会执行并返回结果
    * ormcache会基于mode参数的值来存储结果
* 当使用相同的mode值再次调用该方法时
    * 该方法不会执行，结果会直接从缓存中返回

##### 依赖环境属性
* 方法的结果依赖于环境属性
* 示例
    ```python
    @tools.ormcache('self.env.uid', 'mode')
    def fetch_data(self, mode):
        # 一些计算
        return result
    ```
* ormcache会基于环境中的用户和mode值来保存缓存


#### ormcache_context
* 工作方式类似于ormcache，除了该装饰符还依赖于上下文中的值
* 使用该装饰符时，需要传入参数名和一个上下文键的列表
* 示例
    ```python
    @tools.ormcache_context('mode', keys=('website_id','lang'))
    def fetch_data(self, mode):
        # 一些计算
        return result
    ```
* 示例方法的输出依赖于上下文中的lang、website_id键


#### ormcache_multi
##### 概述
* 某些方法需要在多个记录或多个ID上执行操作
* 如果需要在这些方法上加入缓存，就需要使用该装饰符
* 使用该装饰符时需要传入multi参数
* 在方法调用过程中，orm会通过遍历这些参数来生成缓存键
* 在方法中，你需要以字典的格式返回结果，并使用multi参数的元素来作为键
* 示例
    ```python
    @tools.ormcache_multi('mode', multi='ids')
    def fetch_data(self, mode, ids):
        result = {}
        for i in ids:
            data = ... # 基于ids进行一些计算
            result[i] = data
        return result
    ```

##### 运行方式
* 设想使用[1,2,3]作为参数ids值来调用该方法
* 该方法会返回这种格式的结果 {1:...,2:...,3:...}
* orm库会基于这些键来进行缓存
* 当下次使用[1,2,3,4,5]作为参数dis来调用该方法
* 你的方法只会接收到[4,5],所以方法会在4，5的ids上执行操作。其他结果会从缓存中获取



### 工作原理
* orm缓存使用字典结构来保存缓存
    * 缓存键：基于被装饰的方法的签名来生成
    * 缓存值：是方法返回的结果
* 例子：当使用x、y参数调用方法，方法返回结果为x+y
    * 缓存会查找这样的记录：{(x,y): x+y}
    * 当下次使用相同的参数调用该方法时，结果会直接从缓存中获取
* orm缓存是一个内存缓存，数据会存储在RAM并占用内存
    * 不要使用ormcache处理大量的数据，像图片和文件

#### 警告
* 使用该装饰符的函数不要返回记录集
    * 如果这么做，会产生一个psycopg2.OperationError错误

#### 纯函数
* orm缓存需要使用在纯函数上
* 纯函数是指一个函数同样的参数会返回同样的结果
    * 方法的输出只依赖于输入参数
* 如果函数不是一个纯函数，你需要在执行操作前手动清除缓存
* 清除缓存需要调用clear_caches()
    ```python
    self.env[model_name].clear_caches()
    ```


### 更多
* orm缓存是一个最少使用（LRU）缓存
    * 意味着如果缓存中的键不是经常被使用的，其会被移除
* 如果你不使用orm缓存的该特性，会产生更多的危害
    * 例子：如果传给方法的参数经常会不同，每次Odoo都会先去缓存查找，再调用方法计算
* 如果你想了解缓存如何运行的，可以给odoo进程发送SIGUSR1信息，odoo会输出缓存日志





## 生成不同尺寸的图片

### 概述
* 巨大尺寸的图片对于任何网站都是棘手的
    * 会增加网页的大小，导致网页加载变慢
    * 会导致差的SEO排名和访问者的丢失



### 如何操作
* 需要模型继承image.mixin
* 示例
    ```python
    class LibraryBook(models.Model) :
        _name = 'library.book'
        _inherit = ['image.mixin']
    ```
* mixin模型会自动给books模型增加5个新字段，来存储不同尺寸图片



### 工作原理
* image.mixin实例会字段给模型增加5个新的二进制字段
* 每个字段会存储不同分辨率的图片
* 字段
    * image_1920，分辨率1920 * 1920
    * image_1024, 分辨率1024 * 1024
    * image_512，分辨率512 * 512
    * image_256, 分辨率256 * 256
    * image_128, 分辨率128 * 128

#### 字段说明
* 所有字段中只有image_1920是可以编辑的
* 其他字段都是只读的，当你改变image_1920字段时，会自动更新

#### 后端视图显示
* 所以在后端的form视图中，需要使用image_1920字段，可以允许用户上传图片
* 但是如果这么做，就需要在form视图中加载一张大图片
* 为了提升性能，我们可以使用image_1920图片，但是显示出一张更小的图片
* 实现语法
    ```xml
    <field name="image_1920" widget="image" 
        options="{'preview_iamge': 'image_128'}"/>
    ```
* 当我们保持图片时，odoo会自动缩放图片，将它们存储在各自的字段中
* form视图会使用转换过的image_128来显示



#### 注意
* image.mixin模型是一个AbstractModel，所以该表不会出现在数据库中
    * 你需要通过在你的模型中继承它来使用
* image.mixin，最大只能存储1920 * 1920分辨率的图片
    * 如果你保存了一张大于该分辨率的图片，odoo会自动将分辨率降低到1920 * 1920
    * odoo会保留图片的解析度，避免出现任何畸变




### 更多
#### 更多分辨率
* 在image.mixin中，你可以获取到特定分辨率的图片，但是如果想使用其他分辨率的图片该怎么做呢
* 你可以使用二进制包装器图片字段
    ```python
    image_1500 = fiels.image("image 1500", max_width=1500, max_height=1500)
    ```
* 以上定义会创建出一个image_1500字段，其中的图片会被缩放到1500 * 1500的分辨率
* 编辑该字段不会改变image.mixin中的其他图片字段
    * 如果你想链接到一个image.mixin字段上，可以在定义时增加 related="image_1920"







## 访问分组数据

### 概述
* 当你想对数据进行统计时，你经常需要在一个分组form中进行，像：月度销售报表、销售员的销售报表
* 手动搜索和分组记录是非常耗时的
* 本节将探索read_group()方法


### 如何操作
#### 普通操作
* 设想我们想在联系人form中显示销售订单数，可以通过为每个顾客搜索销售订单，并进行计数来实现
* 示例
    ```python
    # 在 res.partner 模型
    so_count = fields.Integer(compute='_compute_so_count', string='Sale order count')

    def _compute_so_count(self):
        sale_orders = self.env['sale.order'].search(domain=[('partner_id', 'in', self.ids)])
        for partner in self:
            partner.so_count = len(sale_orders.filtered(lambda so: so.partner_id.id == partner.id))
    ```
* 该示例代码可以工作，但是可以优化
* 当在列表视图显示so_count字段时，列表中的所有联系人都会进行读取记录、过滤记录的操作
* 对于小数据量reaad_group()看不出有什么不同，但是对于大数据量这会导致问题


#### read_group操作
* 示例
    ```python
    # 在 res.partner 模型
    so_count = fields.Integer(compute='_compute_so_count', string='Sale order count')

    def _compute_so_count(self):
        sale_data = self.env['sale.order'].read_group(
                domain=[('partner_id', 'in', self.ids)],
                fields=['partner_id'], groupby=['partner_id'])
        mapped_data = dict([(m['partner_id'][0], m['partner_id_count']) for m in sale_data])
        for partner in self:
            partner.so_count = mapped_data[partner.id]
    ```
* 该代码功能和前一个一样，但是只会消耗一次SQL查询
* 该代码直接使用了SQL的 GROUP BY特性



### 工作原理
* read_group()内部使用了GROUP BY的SQL特征，这会使read_group()很快速，即使在大数据集的情况下
* odoo的web客户端在charts视图和分组列表视图中也使用了该方法
* 你可以通过不同参数来改变read_group()的行为


#### 方法说明
* 原型 def read_group(self, domain, fields, groupby, offset=0, limit=None, orderby=False, lazy=True)
* 参数
    * domain: 用于过滤记录，这个是该方法的搜索条件
    * fields: 一个字段列表，用于在分组中获取数据
        * 该字段也需要出现在groupby参数中，除非你使用聚合函数
    * groupby: 一个字段列表，记录会根据该字段进行分组
        * 该参数可以基于多个字段进行分组
    * offset: 用于分页操作，如果你想忽略一些记录，可以使用该参数
    * limit: 用于分页操作，标明了读取记录的最大个数
    * lazy: 默认值为true
        * true: 只会使用groupby参数中的第一个字段进行分组
        * false: 会使用groupby参数中的所有字段进行分组


#### 聚合函数
* read_group支持SQL的聚合函数
* 示例1
    ```python
    self.env['sale.order'].read_group([], 
            ['partner_id', 'amount_total:avg'], 
            ['partner_id'])
    ```
    * 该代码用于获取每个顾客的平均订单数
    * 格式 field_name:agg
* 示例2
    ```python
    self.env['sale.order'].read_group([], 
            ['partner_id', 'total:sum(amount_total)', 'avg_total:avg(amount_total)'], 
            ['partner_id'])
    ```
    * 该代码用于对同一个字段使用不同的聚合函数，获取每个顾客的总订单数和平均订单数
    * 格式  alias:agg(field_name)



### 更多
* 对于日期字段的分组会更复杂一点，因为可能会基于天、星期、季度、月、年来进行记录分组
* 你可以在groupby参数中，使用冒号来传入groupby_function来改变日期字段的分组行为
* 示例
    ```python
    self.env['sale.order'].read_group([], 
            ['total:sum(amount_total)'], 
            ['order_date:month'])
    ```
    * 可用的选项：day, week, month, quarter, year




## 创建/写入多条记录

### 如何操作
#### 创建多条记录
* odoo支持批量创建记录
* 如果创建一条记录，只需要简单的传入一个字段值的字典就可以了
* 要批量创建记录，需要传入一个字典的列表
* 示例
    ```python
    vals = [{
        'name': "Book1",
        'date_release': '2018/12/12',
    }, {
        'name': "Book2",
        'date_release': '2018/12/12',
    }, {
        'name': "Book3",
        'date_release': '2018/12/12',
    }]
    self.env['library.book'].create(vals)
    ```

#### 写入多条记录
* 如果你工作在多个Odoo版本上，你就需要关注一下write方法的运行方式了
* 在odoo13中，odoo处理write的方式不同了，对于更新使用了延时策略
    * 不会立刻将数据写入数据库
    * 只会在必要时、调用flush()时，Odoo才会将数据写入数据库
* 示例1
    ```python
    data = {...}
    for record in recordset:
        record.write(data)
    ```
* 示例2
    ```python
    data = {...}
    recordset.write(data)
    ```
* 如果你在使用老版本的Odoo，示例2会比示例1块很多，因为示例1每次迭代都会执行一次SQL查询



### 工作原理
* 为了批量创建多条记录，你需要将值字典作为列表传入来创建新记录
* 系统会自动的管理批量创建记录
* 当你批量创建记录时，系统内部会为每条记录插入一条查询语句
    * 意味着批量创建记录不会在一条语句中完成
    * 但是并不意味着批量创建记录没有提升性能
    * 性能提升通过批量执行可计算字段来达成


#### write方法
* write的大部分操作都又框架自动完成
* 例子：如果你对所有记录都写相同的数据，数据库只会被一个UPDATE语句更新
    * 如果你在相同事务中一次又一次的更新相同的记录，框架会继续这么处理
* 示例
    ```python
    recordset.name= 'Admin'
    recordset.email= 'admin@example.com'
    recordset.name= 'Administrator'
    recordset.email= 'admin-2@example.com'
    ```
* 上面的代码中，只有一条查询会被作为write来执行，值为name=Administrator和email=admin-2@example.com


#### flush方法
* 示例
    ```python
    recordset.name= 'Admin'
    recordset.email= 'admin@example.com'
    recordset.flush()
    recordset.name= 'Administrator'
    recordset.email= 'admin-2@example.com'
    ```
* flush方法会从缓存中将值更新到数据库中
* 上面的代码中，会执行两次UPDATE语句
    * 第一条语句处理flush前的数据
    * 第二条语句处理flush后的数据



### 更多
* 延时更新只有在odoo13后才有
* 如果使用老版本的odoo， 每写一个值都会立刻执行UPDATE语句
* 错误示例
    ```python
    recordset.name = 'Admin'
    recordset.email = 'admin@example.com'
    ```
* 正确示例
    ```python
    recordset.write({
        'name':'Admin',
        'email':'admin@example.com'
    })
    ```
* 错误示例会执行两条UPDATE语句，正确示例只会执行一条UPDATE语句





## 通过数据库查询访问记录

### 概述
* odoo的ORM库的方法会有限制，有时候通过ORM查询特定数据会比较困难
* 例子：以特定格式读取数据，在数据上执行操作，获得特定结果
    * 这些操作会导致orm库变慢
    * 要处理这些特定情况，可以在数据中执行SQL查询


### 如何操作
使用self._cr.execute()来执行数据库查询
1. 增加以下代码
    ```python
    self.flush()
    self._cr.execute("SELECT id,name,date_release FROM library_book WHERE name ilike %s", ('%odoo%'))

    data = self._cr.fetchall()
    print(data)
    ```
    输出数据
    ```python
    [(7, 'Odoo basics', datetime.date(2018, 2, 15)), 
     (8, 'Odoo 11 Development Cookbook', datetime.date(2018, 2, 15)), 
     (1, 'Odoo 12 Development Cookbook', datetime.date(2019, 2, 13))]
    ```
1. 查询的结果以元组列表的形式返回
    * 元组中的数据和查询中的字段顺序一致
    * 如果想获取字典格式，需要使用dictfetchall()
1. dictfetchal()
    ```python
    self.flush()
    self._cr.execute("SELECT id,name,date_release FROM library_book WHERE name ilike %s", ('%odoo%'))

    data = self._cr.dictfetchall()
    print(data)
    ```
    输出数据
    ```python
    [{'id': 7, 'name': 'Odoo basics', 'date_release': datetime.date(2018, 2, 15)}, 
    {'id': 8, 'name': 'Odoo 11 Development Cookbook', 'date_release': datetime.date(2018, 2, 15)}, 
    {'id': 1, 'name': 'Odoo 12 Development Cookbook', 'date_release': datetime.date(2019, 2, 13)}]
    ```
1. 如果只想获取一条记录，你可以使用fetchone()和dictfetchone()方法
    * 该方法类似于fetchall()和dictfetchall()，但是只返回一条记录




### 工作原理
* 有两种方法可以从记录集中获取到数据库游标
    1. 从记录集本身获取，像：self._cr
    1. 执行环境中获取，像：self.env._cr
* 游标可以用于执行数据查询
    * 数据库的名字需要使用'_'替换'.'，像：library.book 变成 library_book


#### flush操作
* 我们在执行一次查询前使用了self.flush()
    * 这么做是因为odoo大量使用了缓存，数据库可能不会包含正确的值
* self.flush()会将所有延时更新刷入数据库，执行所有依赖这些值的计算，就可以从数据库获取到正确值了。
* flush也支持少量参数，来控制要刷入的数据
    * fname: 一个要刷入的字段名列表
    * record: 一个要刷入的记录集
* 如果执行了INSERT和UPDATE查询，也需要在执行查询后执行一次flush()
    * 因为ORM库可能不会感知到你造成的变动，也许该记录在缓存中


#### 考虑点
在执行原始查询前需要考虑以下几点
* 只有在没有其他选择的情况下，才使用原始查询
* 执行原始查询会绕过ORM层
    * 绕过安全规则、性能提升
    * 错误的构建查询语句还会引入SQL注入风险

#### 语句构建方法
* 错误方法
    ```python
    self.env.cr.execute('SELECT id, name FROM library_book WHERE name ilike'
                        + search_keyword + ';')
    ```
* 正确方法
    ```python
    self.env.cr.execute('SELECT id, name FROM library_book WHERE name ilike %s ';'',
                        (search_keyword,))
    ```

#### 加速操作
* 许多Odoo开发者相信执行SQL查询由于绕过了ORM层，会使操作变快
* 这并不是完全正确的，这依赖于所处的场景
* 大多数操作，ORM执行的都比原始查询要更好、更快。因为会有记录集缓存特性存在


### 更多
* 在一次事务中，只有在事务结束时数据才会被提交
* 如果ORM中发生了错误，事务会进行回滚操作
* 如果你执行了INSERT、UPDATE操作，你想让结果持久化，就需要使用self._cr.commite()来提交这些修改

#### 注意
* 使用commit()是危险的，因为该操作会导致记录处于一种不一致的状态中
* ORM中出现错误会导致不完整的回滚，所以只有在完全确定你要做什么的时候才调用commit()
* 如果使用了commit()，就不在需要使用flush()
     * commont()内部会进行刷入操作
